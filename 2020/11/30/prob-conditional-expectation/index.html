<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="LIN Zeqin's Blogs" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="[Notes] Probability: Theory and Examples by Rick Durrett.">
<meta property="og:type" content="article">
<meta property="og:title" content="Conditional Expectation">
<meta property="og:url" content="http://yoursite.com/2020/11/30/prob-conditional-expectation/index.html">
<meta property="og:site_name" content="LIN Zeqin&#39;s Blogs">
<meta property="og:description" content="[Notes] Probability: Theory and Examples by Rick Durrett.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-11-30T13:15:27.000Z">
<meta property="article:modified_time" content="2020-12-01T13:14:25.807Z">
<meta property="article:author" content="LIN Zeqin">
<meta property="article:tag" content="Conditional Expectation">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2020/11/30/prob-conditional-expectation/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Conditional Expectation | LIN Zeqin's Blogs</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LIN Zeqin's Blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">?</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/30/prob-conditional-expectation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LIN Zeqin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LIN Zeqin's Blogs">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Conditional Expectation
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-30 21:15:27" itemprop="dateCreated datePublished" datetime="2020-11-30T21:15:27+08:00">2020-11-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-01 21:14:25" itemprop="dateModified" datetime="2020-12-01T21:14:25+08:00">2020-12-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Probability-and-Measure/" itemprop="url" rel="index">
                    <span itemprop="name">Probability and Measure</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>[Notes] <u>Probability: Theory and Examples</u> by Rick Durrett.</p>
<a id="more"></a>
<h2 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h2><p>Given a probability space $(\Omega, \mathcal{F}_0, \mathbb{P})$, a $\sigma$-field $\mathcal{F} \subset \mathcal{F}_0$, and a random variable $X \in \mathcal{F}_0$ with $\mathbb{E}|X| &lt; \infty$, define the <strong>conditional expectation</strong> of $X$ given $\mathcal{F}$, $\mathbb{E}(X|\mathcal{F})$, to be any random variable $Y$ that has</p>
<ul>
<li>$Y \in \mathcal{F}$, that is, $Y$ is $\mathcal{F}$-measurable.</li>
<li>For all $A \in \mathcal{F}$,<script type="math/tex; mode=display">
  \int_A X \mathrm{d} \mathbb{P} = \int_A Y \mathrm{d} \mathbb{P}.</script></li>
</ul>
<p>Any $Y$ satisfying the two conditions above is said to be a version of $\mathbb{E}(X|\mathcal{F})$.</p>
<h3 id="Integrability"><a href="#Integrability" class="headerlink" title="Integrability"></a>Integrability</h3><p>If $Y$ is a version of $\mathbb{E}(X|\mathcal{F})$, then it is integrable with $\mathbb{E}|Y| \leq \mathbb{E}|X| &lt; \infty$.</p>
<h3 id="Uniqueness"><a href="#Uniqueness" class="headerlink" title="Uniqueness"></a>Uniqueness</h3><p>If $Y$ and $Y^\prime$ are two versions of $\mathbb{E}(X|\mathcal{F})$, then $Y = Y^\prime$, a.s.</p>
<blockquote>
<p>Since $Y$ and $Y^\prime$ are versions of $\mathbb{E}(X|\mathcal{F})$, we have</p>
<script type="math/tex; mode=display">
\int_A Y \mathrm{d} \mathbb{P} = \int_A X \mathrm{d} \mathbb{P} = \int_A Y^\prime \mathrm{d} \mathbb{P}, \quad \forall A \in \mathcal{F}.</script><p>For any $\varepsilon &gt; 0$, let $A = \{ Y - Y^\prime \geq \varepsilon \} \in \mathcal{F}$. Then we have</p>
<script type="math/tex; mode=display">
0 = \int_A Y \mathrm{d} \mathbb{P} - \int_A Y^{\prime} \mathrm{d} \mathbb{P} = \int_A (Y - Y^\prime) \mathrm{d} \mathbb{P} \geq \varepsilon \mathbb{P}(A),</script><p>so $\mathbb{P}(A) = 0$. Since this holds for all $\varepsilon &gt; 0$, we have $Y \leq Y^\prime$, a.s. Interchanging the roles of $Y$ and $Y^\prime$, we can conclude that $Y = Y^\prime$, a.s.</p>
</blockquote>
<p>If $X = X^\prime$ on $B \in \mathcal{F}$, then $\mathbb{E}(X|\mathcal{F}) = \mathbb{E}(X^\prime|\mathcal{F})$ a.s. on $B$.</p>
<blockquote>
<p>Write $Y = \mathbb{E}(X|\mathcal{F})$ and $Y^\prime = \mathbb{E}(X^\prime|\mathcal{F})$. Then, for any $A \in \mathcal{F}$ with $A \subset B$, we have</p>
<script type="math/tex; mode=display">
\int_A Y \mathrm{d} \mathbb{P} = \int_A X \mathrm{d} \mathbb{P}
= \int_A X^\prime \mathrm{d} \mathbb{P} =\int_A Y^\prime \mathrm{d} \mathbb{P}.</script><p>For any $\varepsilon &gt; 0$, let $A = B \bigcap \{  Y - Y^\prime \geq \varepsilon \} \in \mathcal{F}$. Then we have</p>
<script type="math/tex; mode=display">
0 = \int_A Y \mathrm{d} \mathbb{P} - \int_A Y^{\prime} \mathrm{d} \mathbb{P} = \int_A (Y - Y^\prime) \mathrm{d} \mathbb{P} \geq \varepsilon \mathbb{P}(A),</script><p>so $\mathbb{P}(A) = 0$. Since this holds for all $\varepsilon &gt; 0$, we have $Y \leq Y^\prime$ on $B$, a.s. Interchanging the roles of $Y$ and $Y^\prime$, we can conclude that $Y = Y^\prime$ on $B$, a.s.</p>
</blockquote>
<h3 id="Existence"><a href="#Existence" class="headerlink" title="Existence"></a>Existence</h3><p>The conditional expectation of $X$ given $\mathcal{F}$ exists.</p>
<blockquote>
<p><strong>Non-negative Case</strong></p>
<p>Suppose first that $X \geq 0$. Let $\mu = \mathbb{P}$ and</p>
<script type="math/tex; mode=display">
\nu (A) = \int_A X \mathrm{d} \mu = \int_A X \mathrm{d} \mathbb{P}, \quad \forall A \in \mathcal{F}.</script><p>Then $\nu$ is a finite measure on $\mathcal{F}$ since</p>
<ul>
<li>$\nu(A) \geq 0$ for any $A \in \mathcal{F}$.</li>
<li>$\nu(\varnothing) = 0$.</li>
<li>$\nu(\Omega) = \mathbb{E} X &lt; \infty$.</li>
<li>If $\{ A_n \}_{n=1}^{\infty} \subset \mathcal{F}$ are pairwise disjoint and $A = \bigcup_{n=1}^\infty A_i$, then <script type="math/tex; mode=display">
  \nu \left ( A \right ) = \int_{\Omega} (X \cdot \mathbb{I}_A) \mathrm{d} \mu 
  = \int_{\Omega} \left ( X \cdot \sum_{n=1}^\infty \mathbb{I}_{A_n} \right ) \mathrm{d} \mu = \sum_{n=1}^\infty \int_{\Omega} (X \cdot \mathbb{I}_{A_n}) \mathrm{d} \mu = \sum_{n=1}^\infty \nu \left ( A_n \right ),</script>  where we use the monotone convergence theorem in the third equality.</li>
</ul>
<p>Now for any $A \in \mathcal{F}$ with $\mu(A) = 0$, we have $\nu(A) = 0$, which means that $\nu \ll \mu$, i.e., $\nu$ is absolutely continuous with respect to $\mu$. Therefore, we have the Radon-Nikodym derivative $\mathrm{d} \nu / \mathrm{d} \mu$ which satisfies</p>
<ul>
<li>$\mathrm{d} \nu / \mathrm{d} \mu \in \mathcal{F}$.</li>
<li>For any $A \in \mathcal{F}$,<script type="math/tex; mode=display">
  \int_A X \mathrm{d} \mathbb{P} = \nu(A) = \int_A \frac{\mathrm{d} \nu}{\mathrm{d} \mu} \mathrm{d} \mu = \int_A \frac{\mathrm{d} \nu}{\mathrm{d} \mu} \mathrm{d} \mathbb{P}.</script></li>
</ul>
<p>In conclusion, $\mathrm{d} \nu / \mathrm{d} \mu$ is a version of $\mathbb{E}(X|\mathcal{F})$.</p>
<p><strong>General Case</strong></p>
<p>For the general case, write $X = X^+ - X^-$, and let $Y_1 = \mathbb{E}(X^+ | \mathcal{F})$ and $Y_2 = \mathbb{E}(X^- | \mathcal{F})$. Then,</p>
<ul>
<li>$Y_1 - Y_2 \in \mathcal{F}$.</li>
<li>For any $A \in \mathcal{F}$,</li>
</ul>
<script type="math/tex; mode=display">
\begin{align*}
\int_A X \mathrm{d} \mathbb{P} = \int_A X^+ \mathrm{d} \mathbb{P} - \int_A X^- \mathrm{d} \mathbb{P} = \int_A Y_1 \mathrm{d} \mathbb{P} - \int_A Y_2 \mathrm{d} \mathbb{P} = \int_A (Y_1 - Y_2) \mathrm{d} \mathbb{P}.
\end{align*}</script></blockquote>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><h3 id="Perfect-information"><a href="#Perfect-information" class="headerlink" title="Perfect information"></a>Perfect information</h3><p>If $X \in \mathcal{F}$, then $\mathbb{E}(X | \mathcal{F}) = X$.</p>
<h3 id="No-information"><a href="#No-information" class="headerlink" title="No information"></a>No information</h3><p>Suppose $X$ is independent of $\mathcal{F}$, that is, for all $B \in \mathcal{R}$ and $\mathcal{F}$,</p>
<script type="math/tex; mode=display">
\mathbb{P} \left ( \{ X \in B \} \cap A \right ) = \mathbb{P} \left ( X \in B \right ) \mathbb{P} \left ( A \right ).</script><p>In this case, we have $\mathbb{E}(X | \mathcal{F}) = \mathbb{E}X$.</p>
<blockquote>
<p>Note that</p>
<ul>
<li>$\mathbb{E}X \in \mathcal{F}$.</li>
<li>If $A \in \mathcal{F}$, then $X$ and $\mathbb{I}_A \in \mathcal{F}$ are independent, which implies that<script type="math/tex; mode=display">
  \int_A X \mathrm{d} \mathbb{P} = \mathbb{E} (X \cdot \mathbb{I}_A) = \mathbb{E} X \cdot \mathbb{E} \mathbb{I}_A = \int_A \mathbb{E} X \mathrm{d} \mathbb{P}.</script></li>
</ul>
</blockquote>
<h3 id="Conditional-Probability-amp-Bayes’-Formula"><a href="#Conditional-Probability-amp-Bayes’-Formula" class="headerlink" title="Conditional Probability &amp; Bayes’ Formula"></a>Conditional Probability &amp; Bayes’ Formula</h3><p>For a event $A \in \mathcal{F}_0$, the conditional expectation $\mathbb{E}(\mathbb{I}_A | \mathcal{F})$ is call the <strong>conditional probability</strong> of $A$ given $\mathcal{F}$, denoted by $\mathbb{P}(A | \mathcal{F})$.</p>
<p><strong>Bayes’ theorem</strong> states that, for any $A \in \mathcal{F}_0$ and $B \in \mathcal{F}$, we have</p>
<script type="math/tex; mode=display">
\mathbb{P} (B | A) = \int_B \mathbb{P}(A | \mathcal{F}) \mathrm{d} \mathbb{P} \bigg / \int_{\Omega} \mathbb{P}(A | \mathcal{F}) \mathrm{d} \mathbb{P}.</script><blockquote>
<p>By definition of $\mathbb{P}(A | \mathcal{F})$,  we have</p>
<script type="math/tex; mode=display">
\int_B \mathbb{P}(A | \mathcal{F}) \mathrm{d} \mathbb{P} 
= \int_B \mathbb{I}_A \mathrm{d} \mathbb{P} = \mathbb{P} ( A \cap B )</script><p>and</p>
<script type="math/tex; mode=display">
\int_\Omega \mathbb{P}(A | \mathcal{F}) \mathrm{d} \mathbb{P} 
= \int_\Omega \mathbb{I}_A \mathrm{d} \mathbb{P} = \mathbb{P} \left ( A \right ).</script></blockquote>
<h3 id="Bayes’-Formula-for-sigma-field-Generated-by-Partition"><a href="#Bayes’-Formula-for-sigma-field-Generated-by-Partition" class="headerlink" title="Bayes’ Formula for $\sigma$-field Generated by Partition"></a>Bayes’ Formula for $\sigma$-field Generated by Partition</h3><p>Suppose $\{ \Omega_n \} \subset \mathcal{F}_0$ is a finite or countably infinite partition of $\Omega$ into disjoint sets, each of which has positive probability. Let</p>
<script type="math/tex; mode=display">
\mathcal{F} = \sigma ( \{ \Omega_n \} ) = \left \{ \bigcup_{k=1}^K \Omega_{n_k} :
0 \leq K \leq \infty, \ \{ n_k \}_{k=1}^K \subset \mathbb{Z}_+ \text{ is strictly increasing} \right \}</script><p>be the $\sigma$-field generated by these sets. Then</p>
<script type="math/tex; mode=display">
\mathbb{E}(X|\mathcal{F}) = \sum_{n} \frac{\mathbb{E}(X; \Omega_n)}{\mathbb{P}(\Omega_n)} \mathbb{I}_{\Omega_n}.</script><p>In this situation, Bayes’ formula reduces to, for any $A \in \mathcal{F}_0$,</p>
<script type="math/tex; mode=display">
\mathbb{P} (\Omega_k | A) = \mathbb{P} (A | \Omega_k) \mathbb{P} (\Omega_k) \bigg / \sum_n \mathbb{P} (A | \Omega_n) \mathbb{P} (\Omega_n).</script><blockquote>
<p>Note that</p>
<ul>
<li>The random variable is constant on each $\Omega_n$, so it is measurable with respect to $\mathcal{F}$.</li>
<li>By the construction of $\mathcal{F}$, it is enough to check $\mathbb{E} (\mathbb{E}(X|\mathcal{F}); A)$ for each $A = \Omega_k$, which is trivial since<script type="math/tex; mode=display">
  \int_{\Omega_k} \left ( \sum_{n} \frac{\mathbb{E}(X; \Omega_n)}{\mathbb{P}(\Omega_n)} \mathbb{I}_{\Omega_n} \right ) \mathrm{d} \mathbb{P} 
  = \int_{\Omega_k} \frac{\mathbb{E}(X; \Omega_k)}{\mathbb{P}(\Omega_k)} \mathrm{d} \mathbb{P} 
  = \mathbb{E}(X; \Omega_k)
  = \int_{\Omega_k} X \mathrm{d} \mathbb{P}.</script></li>
</ul>
<p>In this situation, for any $A \in \mathcal{F}_0$, we have</p>
<script type="math/tex; mode=display">
\mathbb{P}(A | \mathcal{F}) = \mathbb{E}(\mathbb{I}_A | \mathcal{F}) = \sum_{n} \frac{\mathbb{E}(\mathbb{I}_A; \Omega_n)}{\mathbb{P}(\Omega_n)} \mathbb{I}_{\Omega_n}
= \sum_{n} \mathbb{P}(A | \Omega_n) \mathbb{I}_{\Omega_n}.</script><p>The Bayes’ formula follows.</p>
</blockquote>
<h3 id="Conditional-Expectation-Given-Random-Variables"><a href="#Conditional-Expectation-Given-Random-Variables" class="headerlink" title="Conditional Expectation Given Random Variables"></a>Conditional Expectation Given Random Variables</h3><p>Let $X, Y \in \mathcal{F}_0$ be two $\mathcal{F}_0$-measurable random variables. The <strong>conditional expectation</strong> of $X$ given $Y$, $\mathbb{E}(X|Y)$ is defined to be $\mathbb{E}(X|\sigma(Y))$, where $\sigma(Y)$ is the $\sigma$-field generated by $Y$.</p>
<h3 id="Conditional-Expectation-Given-Random-Variables-with-Known-Joint-Density"><a href="#Conditional-Expectation-Given-Random-Variables-with-Known-Joint-Density" class="headerlink" title="Conditional Expectation Given Random Variables - with Known Joint Density"></a>Conditional Expectation Given Random Variables - with Known Joint Density</h3><p>Suppose $X$ and $Y$ have joint density $f(x, y)$, that is,</p>
<script type="math/tex; mode=display">
\mathbb{P}((X, Y) \in B) = \int_{B} f(x, y) \mathrm{d} x \mathrm{d} y, \quad \forall B \in \mathcal{R}^{2}.</script><p>In this case, if $\mathbb{E}|g(X)| &lt; \infty$, then $\mathbb{E}(g(X)|Y) = h(Y)$, where</p>
<script type="math/tex; mode=display">
h(y) \int_{\mathbb{R}} f(x, y) \mathrm{d} x = \int_{\mathbb{R}} g(x) f(x, y) \mathrm{d} x.</script><p>Here $h$ can be anything if $\int_{\mathbb{R}} f(x, y) \mathrm{d} x = 0$.</p>
<blockquote>
<p>Let</p>
<script type="math/tex; mode=display">
h_1(y) = \int_{\mathbb{R}} g(x) f(x, y) \mathrm{d} x 
\quad \text{ and } \quad
h_2(y) = \int_{\mathbb{R}} f(x, y) \mathrm{d} x,</script><p>and define $D = \left \{ y \in \mathbb{R}: h_2(y) = 0 \right \}$. </p>
<ul>
<li>Note that by Fubini’s theorem, $h_1$ and $h_2$ are both Borel measurable, so $h_1(Y)$ and $h_2(Y)$ are $\sigma(Y)$-measurable. In addition,<script type="math/tex; mode=display">
  \begin{align*}
  \mathbb{P} \left ( \varphi(Y) = 0 \right ) 
  & = \mathbb{P} (Y \in D) 
  = \mathbb{P}((X, Y) \in \mathbb{R} \times D) \\
  & = \int_{\mathbb{R} \times D} f(x, y) \mathrm{d} x \mathrm{d} y
  = \int_D h_2(y) \mathrm{d} y = 0.
  \end{align*}</script>  Therefore, we have $\varphi(Y) &gt; 0$ a.s., and we can conclude that $h(Y) = h_1(Y) / h_2(Y)$ is $\sigma(Y)$-measurable.</li>
<li>On the other hand, for any $A \in \sigma(Y)$, there exists some $B \in \mathcal{R}$ such that <script type="math/tex; mode=display">
  A = \{ Y \in B \} = \{ (X, Y) \in \mathbb{R} \times B \}.</script>  Using change of variables, we can conclude that<script type="math/tex; mode=display">
  \begin{align*}
  \int_{A} h(Y) \mathrm{d} \mathbb{P}
  & = \int_{ \{ (X, Y) \in \mathbb{R} \times B \} } h(Y) \mathrm{d} \mathbb{P} 
  = \int_B \int_{\mathbb{R}} h(y) f(x, y) \mathrm{d} x \mathrm{d} y \\
  & = \int_B \int_{\mathbb{R}} g(x) f(x, y) \mathrm{d} x \mathrm{d} y
  = \int_{ \{ (X, Y) \in \mathbb{R} \times B \} } g(X) \mathrm{d} \mathbb{P} 
  = \int_{A} g(X) \mathrm{d} \mathbb{P}.
  \end{align*}</script></li>
</ul>
</blockquote>
<h3 id="Conditional-Expectation-Given-Random-Variables-with-Independence"><a href="#Conditional-Expectation-Given-Random-Variables-with-Independence" class="headerlink" title="Conditional Expectation Given Random Variables - with Independence"></a>Conditional Expectation Given Random Variables - with Independence</h3><p>Suppose $X$ and $Y$ are independent. Let $\varphi$ be a function with $\mathbb{E}|\varphi(X,Y)| &lt; \infty$ and let $g(x) = \mathbb{E} \varphi(x, Y)$. Then</p>
<script type="math/tex; mode=display">
\mathbb{E}(\varphi(X, Y)|X) = g(X).</script><blockquote>
<p>Assume that the distribution of $X$ and $Y$ are $\mu$ and $\nu$, respectively.</p>
<ul>
<li>Since $\mathbb{E}|\varphi(X,Y)| &lt; \infty$, by Fubini’s theorem we know that the following map<script type="math/tex; mode=display">
  x \mapsto g(x) = \mathbb{E} \varphi(x, Y) = \int_{\Omega} \varphi(x, Y) \mathrm{d} \mathbb{P} = \int_{\mathbb{R}} \varphi(x, y) \nu (\mathrm{d} y).</script>  is Borel measurable. Thus $g(X)$ is $\sigma(X)$-measurable.</li>
<li>Let $A \in \sigma(X)$. Then there exist a Borel set $B \in \mathcal{R}$ such that $A = \{ X \in B  \}$. Using change of variables and the fact that $X$ and $Y$ are independent, we can conclude that<script type="math/tex; mode=display">
  \begin{align*}
  \int_{A} \varphi(X, Y) \mathrm{d} \mathbb{P} 
  & = \int_{\Omega} \varphi(X, Y) \cdot \mathbb{I}_C(X) \mathrm{d} \mathbb{P} 
  = \int_{\mathbb{R}^2} \varphi(x, y) \cdot \mathbb{I}_C(x) \mathrm{d} (\mu \times \nu) \\
  & = \int_{\mathbb{R}} \int_{\mathbb{R}} \varphi(x, y) \cdot \mathbb{I}_C(x) \nu(\mathrm{d} y) \mu (\mathrm{d} x)
  = \int_{\mathbb{R}} g(x) \mathbb{I}_C(x) \mu (\mathrm{d} x) \\
  & = \int_{\Omega} g(X) \mathbb{I}_C(X) \mathrm{d} \mathbb{P}
  = \int_{A} g(X) \mathrm{d} \mathbb{P}.
  \end{align*}</script></li>
</ul>
</blockquote>
<h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><h3 id="Linearity"><a href="#Linearity" class="headerlink" title="Linearity"></a>Linearity</h3><script type="math/tex; mode=display">
\mathbb{E}(a X + bY | \mathcal{F}) = a \mathbb{E}(X | \mathcal{F}) + b \mathbb{E}(Y | \mathcal{F}).</script><h3 id="Monotonicity"><a href="#Monotonicity" class="headerlink" title="Monotonicity"></a>Monotonicity</h3><p>If $X \leq Y$, then</p>
<script type="math/tex; mode=display">
\mathbb{E}(X | \mathcal{F}) \leq \mathbb{E}(Y | \mathcal{F}).</script><h3 id="Monotone-Converge-Theorem"><a href="#Monotone-Converge-Theorem" class="headerlink" title="Monotone Converge Theorem"></a>Monotone Converge Theorem</h3><p>If $X_n \geq 0$ and $X_n \uparrow X$ with $\mathbb{E}|X| &lt; \infty$, then</p>
<script type="math/tex; mode=display">
\mathbb{E}(X_n | \mathcal{F}) \ \big \uparrow \ \mathbb{E}(X | \mathcal{F}).</script><blockquote>
<p>By monotonicity of conditional expectation, we know that $\mathbb{E}(X_n | \mathcal{F})$ is increasing. Let</p>
<script type="math/tex; mode=display">
Z = \sup_{n} \mathbb{E}(X_n | \mathcal{F}) \in \mathcal{F}.</script><p>Then by the monotone convergence theorem, for any $A \in \mathcal{F}$, we have</p>
<script type="math/tex; mode=display">
\int_A Z \mathrm{d} \mathbb{P}
= \lim_{n \to \infty} \int_A \mathbb{E}(X_n | \mathcal{F}) \mathrm{d} \mathbb{P}
= \lim_{n \to \infty} \int_A X_n \mathrm{d} \mathbb{P} 
= \int_A X \mathrm{d} \mathbb{P} 
= \int_A \mathbb{E}(X | \mathcal{F}) \mathrm{d} \mathbb{P}.</script><p>Since $\mathbb{E}|X| &lt; \infty$, the equality above gives</p>
<script type="math/tex; mode=display">
\int_A \big [ Z - \mathbb{E}(X | \mathcal{F}) \big ] \mathrm{d} \mathbb{P} = 0,
\quad \forall A \in \mathcal{F},</script><p>which implies $Z - \mathbb{E}(X | \mathcal{F}) = 0$ a.s. since both $Z$ and $\mathbb{E}(X | \mathcal{F})$ are $\mathcal{F}$-measurable.</p>
</blockquote>
<p>If $X_n \downarrow X$ with $\mathbb{E}|X|, \mathbb{E}|X_1| &lt; \infty$, then</p>
<script type="math/tex; mode=display">
\mathbb{E}(X_n | \mathcal{F}) \ \big \downarrow \ \mathbb{E}(X | \mathcal{F}).</script><h3 id="Law-of-total-probability"><a href="#Law-of-total-probability" class="headerlink" title="Law of total probability"></a>Law of total probability</h3><p>Assume that $\mathbb{E}|X| &lt; \infty$, then we have</p>
<script type="math/tex; mode=display">
\mathbb{E}(X) = \mathbb{E} (\mathbb{E}(X | \mathcal{F})).</script><p>When $X = \mathbb{I}_A$ for some $A \in \mathcal{F}_0$ and $\mathcal{F}$ is generated by $\{ \Omega_n \} \subset \mathcal{F}_0$, a partition of $\Omega$, this becomes</p>
<script type="math/tex; mode=display">
\mathbb{P} (A) = \sum_{n} \mathbb{P}(A | \Omega_n) \mathbb{P} (\Omega_n).</script><h3 id="Order-of-sigma-field"><a href="#Order-of-sigma-field" class="headerlink" title="Order of $\sigma$-field"></a>Order of $\sigma$-field</h3><p>If $\mathcal{F} \subset \mathcal{G}$ and $\mathbb{E}(X|\mathcal{G}) \in \mathcal{F}$, then $\mathbb{E}(X|\mathcal{G}) = \mathbb{E}(X|\mathcal{F})$.</p>
<blockquote>
<p>Notice that we have $\mathbb{E}(X|\mathcal{G}) \in \mathcal{F}$ and for any $A \in \mathcal{F} \subset \mathcal{G}$,</p>
<script type="math/tex; mode=display">
\int_A \mathbb{E}(X|\mathcal{G}) \mathrm{d} \mathbb{P} 
= \int_A X \mathrm{d} \mathbb{P}.</script></blockquote>
<p>If $\mathcal{F}_1 \subset \mathcal{F}_2$, then</p>
<ul>
<li>$\mathbb{E} \big ( \mathbb{E}(X|\mathcal{F}_1) \big | \mathcal{F}_2 \big ) = \mathbb{E}(X|\mathcal{F}_1)$,</li>
<li>$\mathbb{E} \big ( \mathbb{E}(X|\mathcal{F}_2) \big | \mathcal{F}_1 \big ) = \mathbb{E}(X|\mathcal{F}_1)$.</li>
</ul>
<blockquote>
<p>For the first one, we are in the same place as the example of perfect information since we have</p>
<script type="math/tex; mode=display">
\mathbb{E}(X|\mathcal{F}_1) \in \mathcal{F}_1 \subset \mathcal{F}_2.</script><p>For the second one, note that $\mathbb{E}(X|\mathcal{F}_1) \in \mathcal{F}_1$, and for any $A \in \mathcal{F}_1 \subset \mathcal{F}_2$, we have</p>
<script type="math/tex; mode=display">
\int_A \mathbb{E}(X|\mathcal{F}_1) \mathrm{d} \mathbb{P} = \int_A X \mathrm{d} \mathbb{P} = \int_A \mathbb{E}(X|\mathcal{F}_2) \mathrm{d} \mathbb{P}.</script></blockquote>
<p>If $X \in \mathcal{F}$ and $\mathbb{E} |Y|, \mathbb{E}|XY| &lt; \infty$,then</p>
<script type="math/tex; mode=display">
\mathbb{E}(XY | \mathcal{F}) = X \mathbb{E}(Y|\mathcal{F}).</script><h3 id="Chebyshev’s-inequality"><a href="#Chebyshev’s-inequality" class="headerlink" title="Chebyshev’s inequality"></a>Chebyshev’s inequality</h3><script type="math/tex; mode=display">
\mathbb{P} (|X| \geq a | \mathcal{F}) \leq a^{-2} \mathbb{E} \left ( X^2 | \mathcal{F} \right ).</script><blockquote>
<p>Note that $\mathbb{I}_{|X| \geq a} \leq a^{-2} X^2$. Thus by monotonicity of conditional expectation we have</p>
<script type="math/tex; mode=display">
\mathbb{P} (|X| \geq a | \mathcal{F}) 
= \mathbb{E} (\mathbb{I}_{|X| \geq a} | \mathcal{F}) 
\leq \mathbb{E} (a^{-2} X^2 | \mathcal{F})
= \mathbb{E} (X^2 | \mathcal{F}).</script></blockquote>
<h3 id="Cauchy-Schwarz-inequality"><a href="#Cauchy-Schwarz-inequality" class="headerlink" title="Cauchy-Schwarz inequality"></a>Cauchy-Schwarz inequality</h3><p>Assume that $\mathbb{E} X^2, \mathbb{E} Y^2, \mathbb{E}|XY| &lt; \infty$. Then </p>
<script type="math/tex; mode=display">
\mathbb{E}(XY|\mathcal{F})^2 \leq \mathbb{E} \left ( X^2|\mathcal{F} \right ) \mathbb{E} \left ( Y^2|\mathcal{F} \right ).</script><blockquote>
<p>For any $\theta \in \mathbb{Q}$, we have $\mathbb{E} \left ( (X - \theta Y)^2|\mathcal{F} \right ) \geq 0$ a.s. Note that $\mathbb{Q}$ is countable. Thus</p>
<script type="math/tex; mode=display">
\mathbb{E} \left ( X^2|\mathcal{F} \right ) - 2 \theta \cdot \mathbb{E}(XY|\mathcal{F}) + \theta^2 \mathbb{E} \left ( Y^2|\mathcal{F} \right ) \geq 0, 
\quad \forall \theta \in \mathbb{Q}, 
\quad \text{a.s.}</script><p>This implies that,</p>
<script type="math/tex; mode=display">
\mathbb{E}(XY|\mathcal{F})^2 \leq \mathbb{E} \left ( X^2|\mathcal{F} \right ) \mathbb{E} \left ( Y^2|\mathcal{F} \right ), \quad \text{a.s.}</script></blockquote>
<h3 id="Jensen’s-inequality"><a href="#Jensen’s-inequality" class="headerlink" title="Jensen’s inequality"></a>Jensen’s inequality</h3><p>Let $\varphi$ be a convex function on $\mathbb{R}$ and suppose that $\mathbb{E}|X|, \mathbb{E}|\varphi(X)| &lt; \infty$. Then</p>
<script type="math/tex; mode=display">
\varphi(\mathbb{E}(X|\mathcal{F})) \leq \mathbb{E}(\varphi(X)|\mathcal{F}).</script><blockquote>
<p><strong>Properties of Sub-gradient</strong></p>
<p>Assume that $\varphi: \mathbb{R} \to \mathbb{R}$ is convex. Then we have the following properties for the sub-gradient of $\varphi$.</p>
<ul>
<li><strong>Monotonicity</strong>: If $x_1 &lt; x_2$, then for any $g_1 \in \partial \varphi(x_1)$ and $g_2 \in \partial \varphi(x_2)$, we have $g_1 \leq g_2$.</li>
<li><strong>Continuity</strong>: Assume that $x_n \to x$ and $g_n \in \partial \varphi(x_n)$ for each $n$. If $g_n$ converges to $g$, then $g \in \partial \varphi (x)$.</li>
<li><strong>Intermediate Value Theorem</strong>: Assume that $x_1 &lt; x_2$ and $g_1 &lt; g_2$ with $g_i \in \partial \varphi(x_i)$, $i = 1, 2$. Then for any $g_1 &lt; g &lt; g_2$, there exists some $x \in [x_1, x_2]$ such that $g \in \partial \varphi(x)$.</li>
</ul>
<p>For the last statement, we can use binary search to find $x$. For each $n \geq 1$, consider $c_n = (a_n + b_n) / 2$.</p>
<ul>
<li>If $g \in \partial \varphi(c_n)$, then searching is completed.</li>
<li>If $h &gt; g$ for any $h \in \partial \varphi(c_n)$, then let $[a_{n+1}, b_{n+1}] = [a_n, c_n]$.</li>
<li>If $h &lt; g$ for any $h \in \partial \varphi(c_n)$, then let $[a_{n+1}, b_{n+1}] = [c_n, b_n]$.</li>
</ul>
<p>Assume that the searching does not stop in any certain step. In this case, we have a sequence of nested intervals $\{ [a_n, b_n] \}$ whose length converges to $0$, which means that there exists a unique point $x$ with $x \in \bigcap_{n} [a_n, b_n]$. </p>
<p>Now, for each $n$, pick $h_n \in \partial \varphi(a_n)$ and $h_n^\prime \in \partial \varphi(b_n)$. By the construction of $a_n$ and $b_n$, we know that $h_n &lt; g &lt; h_n^\prime$ for each $n$. On the other hand, by the monotonicity of sub-gradients, we know that $h_n$ is non-decreasing and $h_n^\prime$ is non-increasing. Thus $\lim_{n \to \infty} h_n$ and $\lim_{n \to \infty} h_n^\prime$ exist with</p>
<script type="math/tex; mode=display">
\lim_{n \to \infty} h_n \leq g \leq \lim_{n \to \infty} h_n^\prime.</script><p>Finally, since $a_n \uparrow x$ and $b_n \downarrow x$, by the continuity of sub-gradients, we can conclude that</p>
<script type="math/tex; mode=display">
g \in \left [ \lim_{n \to \infty} h_n, \lim_{n \to \infty} h_n^\prime \right ] \subset \partial \varphi (x).</script><p><strong>Lower Envelope Generated by Linear Functions with Rational Coefficients</strong></p>
<p>If $\bigcup_{x \in \mathbb{R}} \partial \varphi (x)$ contains more than one element, then it is a finite or infinite interval with positive length, since by the intermediate value theorem above we know that $\bigcup_{x \in } \partial \varphi (x) \subset \mathbb{R}$ is convex. In this case, the set </p>
<script type="math/tex; mode=display">
S = \left \{ (a, b) \in \mathbb{Q}^2: ax + b \leq \varphi(x) \text { for all } x \in \mathbb{R} \right \}</script><p>is not empty. Now given any $x \in \mathbb{R}$, we claim</p>
<script type="math/tex; mode=display">
\varphi(x) = \sup \{ ax + b : (a, b) \in S \}.</script><p>This is trivial when $\partial \varphi(x) \cap \mathbb{Q} \not= \varnothing$. As for the case $\partial \varphi(x) = \{ g \}$ for some $g \in \mathbb{R} \backslash \mathbb{Q}$, assume that</p>
<script type="math/tex; mode=display">
\varphi(x) - \sup \{ ax + b : (a, b) \in S \} = \varepsilon > 0.</script><p>Since $\bigcup_{x \in \mathbb{R}} \partial \varphi (x)$ is an interval, we can find a $x_1 \in \mathbb{R}$ with $g_1 \in \partial \varphi(x_1) \cap \mathbb{Q}$. If $x_k$ and $g_k \in \partial \varphi(x_1) \cap \mathbb{Q}$ have been defined for all $1 \leq k \leq n$. Since $g_{n} \in \mathbb{Q}$ and $g \notin \mathbb{Q}$, there exists a $g_{n+1}$ such that</p>
<ul>
<li>$g_{n+1} \in \mathbb{Q}$.</li>
<li>$|g_{n+1} - g| &lt; 1/(n+1)$.</li>
<li>$(g_{n+1}-g)(g_{n+1}-g_n) &lt; 0$. In other words, $g_{n+1}$ is strictly between $g$ and $g_n$.</li>
</ul>
<p>By the intermediate value theorem of sub-gradients, we can find $x_{n+1}$ with</p>
<ul>
<li>$(x_{n+1} - x_n)(x_{n+1} - x) \leq 0$. In other words, $x_{n+1}$ is between $x$ and $x_n$.</li>
<li>$g_{n+1} \in \partial \varphi(x_{n+1})$.</li>
</ul>
<p>Now $g_n \to g$ and $\{ x_n \}$ is a monotone sequence bounded by $x_1$ and $x$. Therefore, we can define $x^\prime = \lim_{n \to \infty} x_n$. By the continuity of sub-gradients, we know that $g \in \partial \varphi (x^\prime)$, which means that $\varphi$ is linear between $x$ and $x^\prime$, i.e.</p>
<script type="math/tex; mode=display">
\varphi(x^\prime) - \varphi(x) = g(x^\prime - x).</script><p>On the other hand, there exists a sequence $r_n \uparrow 0$ such that</p>
<script type="math/tex; mode=display">
b_n := \varphi(x_n) - g_n x_n + r_n \in \mathbb{Q}, \quad \forall n \in \mathbb{Z}_+.</script><p>For each $n$, since $g_{n} \in \partial \varphi(x_{n})$ and $r_n \leq 0$, we have</p>
<script type="math/tex; mode=display">
\varphi(y) - \varphi(x_n) \geq g_n (y - x_n) \geq g_n (y - x_n) + r_n, \quad \forall y \in \mathbb{R},</script><p>which implies that $(g_n, b_n) \in S$. By the assumption at beginning, we have</p>
<script type="math/tex; mode=display">
\varphi(x) - \varepsilon \geq g_n x + b_n = g_n x + [\varphi(x_n) - g_n x_n + r_n], \quad \forall n \in \mathbb{Z}_+.</script><p>Letting $n \to \infty$, we obtain</p>
<script type="math/tex; mode=display">
\varphi(x) - \varepsilon \geq \varphi(x^\prime) + g (x - x^\prime),</script><p>which contradicts the observation that $\varphi$ is linear between $x$ and $x^\prime$.</p>
<p><strong>Proof for Jensen’s inequality</strong></p>
<p>If $\bigcup_{x \in \mathbb{R}} \partial \varphi (x)$ contains only one element, then $\varphi$ is linear and the result is trivial. Otherwise, for each $(a, b) \in S$, we have $\varphi(X) \geq aX + b$ and thus</p>
<script type="math/tex; mode=display">
\mathbb{E}(\varphi(X)|\mathcal{F}) \geq a \mathbb{E}(X|\mathcal{F}) + b, \quad \text{a.s.}</script><p>Since $S$ is countable, we have</p>
<script type="math/tex; mode=display">
\mathbb{E}(\varphi(X)|\mathcal{F}) \geq a \mathbb{E}(X|\mathcal{F}) + b, \quad \forall (a, b) \in S, \quad \text{a.s.}</script><p>and thus</p>
<script type="math/tex; mode=display">
\mathbb{E}(\varphi(X)|\mathcal{F}) \geq \sup \big\{ a \mathbb{E}(X|\mathcal{F}) + b : (a,b) \in S \big \} = \varphi(\mathbb{E}(X|\mathcal{F})), \quad \text{a.s.}</script></blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Conditional-Expectation/" rel="tag"># Conditional Expectation</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/11/10/bai-ch2-semicircular-simplification/" rel="next" title="Semicircular Law for Wigner Matrices - Matrix Simplification">
                  <i class="fa fa-chevron-left"></i> Semicircular Law for Wigner Matrices - Matrix Simplification
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/12/26/bai-ch1-stieltjes-transform/" rel="prev" title="Stieltjes Transform">
                  Stieltjes Transform <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Definitions"><span class="nav-number">1.</span> <span class="nav-text">Definitions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Integrability"><span class="nav-number">1.1.</span> <span class="nav-text">Integrability</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uniqueness"><span class="nav-number">1.2.</span> <span class="nav-text">Uniqueness</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Existence"><span class="nav-number">1.3.</span> <span class="nav-text">Existence</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Examples"><span class="nav-number">2.</span> <span class="nav-text">Examples</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Perfect-information"><span class="nav-number">2.1.</span> <span class="nav-text">Perfect information</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#No-information"><span class="nav-number">2.2.</span> <span class="nav-text">No information</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conditional-Probability-amp-Bayes%E2%80%99-Formula"><span class="nav-number">2.3.</span> <span class="nav-text">Conditional Probability &amp; Bayes’ Formula</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bayes%E2%80%99-Formula-for-sigma-field-Generated-by-Partition"><span class="nav-number">2.4.</span> <span class="nav-text">Bayes’ Formula for $\sigma$-field Generated by Partition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conditional-Expectation-Given-Random-Variables"><span class="nav-number">2.5.</span> <span class="nav-text">Conditional Expectation Given Random Variables</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conditional-Expectation-Given-Random-Variables-with-Known-Joint-Density"><span class="nav-number">2.6.</span> <span class="nav-text">Conditional Expectation Given Random Variables - with Known Joint Density</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conditional-Expectation-Given-Random-Variables-with-Independence"><span class="nav-number">2.7.</span> <span class="nav-text">Conditional Expectation Given Random Variables - with Independence</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Properties"><span class="nav-number">3.</span> <span class="nav-text">Properties</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Linearity"><span class="nav-number">3.1.</span> <span class="nav-text">Linearity</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Monotonicity"><span class="nav-number">3.2.</span> <span class="nav-text">Monotonicity</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Monotone-Converge-Theorem"><span class="nav-number">3.3.</span> <span class="nav-text">Monotone Converge Theorem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Law-of-total-probability"><span class="nav-number">3.4.</span> <span class="nav-text">Law of total probability</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Order-of-sigma-field"><span class="nav-number">3.5.</span> <span class="nav-text">Order of $\sigma$-field</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chebyshev%E2%80%99s-inequality"><span class="nav-number">3.6.</span> <span class="nav-text">Chebyshev’s inequality</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cauchy-Schwarz-inequality"><span class="nav-number">3.7.</span> <span class="nav-text">Cauchy-Schwarz inequality</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Jensen%E2%80%99s-inequality"><span class="nav-number">3.8.</span> <span class="nav-text">Jensen’s inequality</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="LIN Zeqin"
    src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">LIN Zeqin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LIN Zeqin</span>
</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv" style='display:none'>
    Total Views: <span id="busuanzi_value_site_pv"></span>
    <span class="post-meta-divider">|</span>
</span>
<span id="busuanzi_container_site_uv" style='display:none'>
    Total Visitors: <span id="busuanzi_value_site_uv"></span>
</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v5.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
